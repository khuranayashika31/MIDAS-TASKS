{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='background :yellow' > MIDAS INTERNSHIP TASK 2 ( Part 1 ) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By: Yashika Khurana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "from PIL import ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please ignore this dictionary for the moment. It was used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary={\n",
    "    \"001\":\"0\",\n",
    "    \"002\":\"1\",\n",
    "    \"003\":\"2\",\n",
    "    \"004\":\"3\",\n",
    "    \"005\":\"4\",\n",
    "    \"006\":\"5\",\n",
    "    \"007\":\"6\",\n",
    "    \"008\":\"7\",\n",
    "    \"009\":\"8\",\n",
    "    \"010\":\"9\",\n",
    "    \"011\":\"A\",\n",
    "    \"012\":\"B\",\n",
    "    \"013\":\"C\",\n",
    "    \"014\":\"D\",\n",
    "    \"015\":\"E\",\n",
    "    \"016\":\"F\",\n",
    "    \"017\":\"G\",\n",
    "    \"018\":\"H\",\n",
    "    \"019\":\"I\",\n",
    "    \"020\":\"J\",\n",
    "    \"021\":\"K\",\n",
    "    \"022\":\"L\",\n",
    "    \"023\":\"M\",\n",
    "    \"024\":\"N\",\n",
    "    \"025\":\"O\",\n",
    "    \"026\":\"P\",\n",
    "    \"027\":\"Q\",\n",
    "    \"028\":\"R\",\n",
    "    \"029\":\"S\",\n",
    "    \"030\":\"T\",\n",
    "    \"031\":\"U\",\n",
    "    \"032\":\"V\",\n",
    "    \"033\":\"W\",\n",
    "    \"034\":\"X\",\n",
    "    \"035\":\"Y\",\n",
    "    \"036\":\"Z\",\n",
    "    \"037\":\"a\",\n",
    "    \"038\":\"b\",\n",
    "    \"039\":\"c\",\n",
    "    \"040\":\"d\",\n",
    "    \"041\":\"e\",\n",
    "    \"042\":\"f\",\n",
    "    \"043\":\"g\",\n",
    "    \"044\":\"h\",\n",
    "    \"045\":\"i\",\n",
    "    \"046\":\"j\",\n",
    "    \"047\":\"k\",\n",
    "    \"048\":\"l\",\n",
    "    \"049\":\"m\",\n",
    "    \"050\":\"n\",\n",
    "    \"051\":\"o\",\n",
    "    \"052\":\"p\",\n",
    "    \"053\":\"q\",\n",
    "    \"054\":\"r\",\n",
    "    \"055\":\"s\",\n",
    "    \"056\":\"t\",\n",
    "    \"057\":\"u\",\n",
    "    \"058\":\"v\",\n",
    "    \"059\":\"w\",\n",
    "    \"060\":\"x\",\n",
    "    \"061\":\"y\",\n",
    "    \"062\":\"z\"   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing : \n",
    "The pre-processing has been done in accordance with the pre-processing performed with the MNIST dataset to convert it into standard form.\n",
    "\n",
    "- Extracting images from the file, appending them to data\n",
    "- Extracting labels from the image names\n",
    "- Converting images to (28,28)\n",
    "\n",
    "#### The following steps in bullets have been taken from Medium blogs \n",
    "\n",
    "- Inverting image color\n",
    "- Normalizing\n",
    "- Removing rows that are completely zero (i.e. black) to extract only the digit part. So that the model doesn't learm extra features.\n",
    "- Fitting image in a 20 rows and columns \n",
    "- Padding images to fit (28,28) size\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "for i in os.listdir(\"train\"):\n",
    "    if str(i)==\".DS_Store\": # DS_Store file gets created automatically, if-condition helps ignore it\n",
    "        pass\n",
    "    else:\n",
    "    \n",
    "        for j in os.listdir(\"train/\"+str(i)):\n",
    "    \n",
    "            link=\"train/\"+str(i)+\"/\"+str(j)\n",
    "         \n",
    "            img=cv2.imread(link)\n",
    "            img = cv2.resize(255-img, (28, 28))\n",
    "            img=img[:,:,-1]\n",
    "            img = img / 255.0\n",
    "            while np.sum(img[0]) == 0:\n",
    "                img = img[1:]\n",
    "\n",
    "            while np.sum(img[:,0]) == 0:\n",
    "                img = np.delete(img,0,1)\n",
    "\n",
    "            while np.sum(img[-1]) == 0:\n",
    "                img = img[:-1]\n",
    "\n",
    "            while np.sum(img[:,-1]) == 0:\n",
    "                img = np.delete(img,-1,1)\n",
    "\n",
    "            rows,cols = img.shape\n",
    "            \n",
    "            if rows > cols:\n",
    "                factor = 20.0/rows\n",
    "                rows = 20\n",
    "                cols = int(round(cols*factor))\n",
    "                gray = cv2.resize(img, (cols,rows))\n",
    "            else:\n",
    "                factor = 20.0/cols\n",
    "                cols = 20\n",
    "                rows = int(round(rows*factor))\n",
    "                gray = cv2.resize(img, (cols, rows))\n",
    "              \n",
    "            colsPadding = (int(math.ceil((28-cols)/2.0)),int(math.floor((28-cols)/2.0)))\n",
    "            rowsPadding = (int(math.ceil((28-rows)/2.0)),int(math.floor((28-rows)/2.0)))\n",
    "            imgf = np.lib.pad(gray,(rowsPadding,colsPadding),'constant')\n",
    "            imgf -= imgf.min() \n",
    "            imgf /= imgf.max()\n",
    "            imgf *= 255 # [0, 255] range\n",
    "            \n",
    "            data.append(imgf)\n",
    "            \n",
    "           \n",
    "            labels.append(str(i)[7:9])\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[\"image\"]=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[\"label\"]=labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting data to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2480, 28, 28)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping data and labels before sending to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.reshape(len(data),28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2480, 28, 28, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2480,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting labels to unint8 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=labels.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.uint8"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffling the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "temp=list(zip(data,labels))\n",
    "random.shuffle(temp)\n",
    "data,labels=zip(*temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.asarray(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a CNN model by using Keras Tuner for Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):  \n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
    "        activation='relu',\n",
    "        input_shape=(28,28,1)\n",
    "    ),\n",
    "    keras.layers.Conv2D(\n",
    "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\n",
    "        activation='relu'\n",
    "    ),\n",
    "   # keras.layers.BatchNormalization(),\n",
    "   # keras.layers.Activation(activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),  #1\n",
    "    keras.layers.Dropout(rate=0.2),  #2\n",
    "      \n",
    "    \n",
    "   \n",
    "    keras.layers.Flatten(), #3\n",
    "    keras.layers.Dense( #4\n",
    "        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n",
    "        activation='relu'\n",
    "    ),\n",
    "    keras.layers.Dense(63, activation='softmax')\n",
    "  ])\n",
    "  \n",
    "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project output/yMidas/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from output/yMidas/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner_search=RandomSearch(build_model,\n",
    "                          objective='val_accuracy',\n",
    "                          max_trials=3,directory='output',project_name=\"yMidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2480, 28, 28, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2480,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching best parameters for 3 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.27419355511665344\n",
      "\n",
      "Best val_accuracy So Far: 0.6532257795333862\n",
      "Total elapsed time: 00h 04m 39s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(data,labels,epochs=3,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting best model\n",
    "( Best model --> The model with best validation accuracy so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tuner_search.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 112)       2912      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 48)        134448    \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4800)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 112)               537712    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 63)                7119      \n",
      "=================================================================\n",
      "Total params: 682,191\n",
      "Trainable params: 682,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.6313 - accuracy: 0.7921 - val_loss: 1.4577 - val_accuracy: 0.6371\n",
      "Epoch 5/20\n",
      "70/70 [==============================] - 8s 110ms/step - loss: 0.4646 - accuracy: 0.8453 - val_loss: 1.4752 - val_accuracy: 0.6371\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - 8s 112ms/step - loss: 0.3648 - accuracy: 0.8811 - val_loss: 1.4895 - val_accuracy: 0.6895\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - 8s 110ms/step - loss: 0.2536 - accuracy: 0.9138 - val_loss: 1.6574 - val_accuracy: 0.6653\n",
      "Epoch 8/20\n",
      "70/70 [==============================] - 8s 112ms/step - loss: 0.2533 - accuracy: 0.9074 - val_loss: 1.8938 - val_accuracy: 0.6694\n",
      "Epoch 9/20\n",
      "70/70 [==============================] - 8s 112ms/step - loss: 0.1998 - accuracy: 0.9320 - val_loss: 1.7701 - val_accuracy: 0.7137\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - 8s 118ms/step - loss: 0.1454 - accuracy: 0.9501 - val_loss: 1.7131 - val_accuracy: 0.6774\n",
      "Epoch 11/20\n",
      "70/70 [==============================] - 8s 115ms/step - loss: 0.1425 - accuracy: 0.9501 - val_loss: 1.8189 - val_accuracy: 0.6774\n",
      "Epoch 12/20\n",
      "70/70 [==============================] - 8s 120ms/step - loss: 0.1350 - accuracy: 0.9453 - val_loss: 1.6299 - val_accuracy: 0.6855\n",
      "Epoch 13/20\n",
      "70/70 [==============================] - 8s 120ms/step - loss: 0.1245 - accuracy: 0.9565 - val_loss: 1.9847 - val_accuracy: 0.6613\n",
      "Epoch 14/20\n",
      "70/70 [==============================] - 9s 122ms/step - loss: 0.0851 - accuracy: 0.9703 - val_loss: 1.9075 - val_accuracy: 0.6976\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - 9s 134ms/step - loss: 0.1167 - accuracy: 0.9578 - val_loss: 1.9940 - val_accuracy: 0.6694\n",
      "Epoch 16/20\n",
      "70/70 [==============================] - 10s 137ms/step - loss: 0.1098 - accuracy: 0.9621 - val_loss: 2.0826 - val_accuracy: 0.6815\n",
      "Epoch 17/20\n",
      "70/70 [==============================] - 9s 123ms/step - loss: 0.1400 - accuracy: 0.9517 - val_loss: 1.8148 - val_accuracy: 0.6734\n",
      "Epoch 18/20\n",
      "70/70 [==============================] - 9s 128ms/step - loss: 0.0889 - accuracy: 0.9680 - val_loss: 2.4283 - val_accuracy: 0.6694\n",
      "Epoch 19/20\n",
      "70/70 [==============================] - 8s 118ms/step - loss: 0.1463 - accuracy: 0.9541 - val_loss: 2.1026 - val_accuracy: 0.6935\n",
      "Epoch 20/20\n",
      "70/70 [==============================] - 8s 111ms/step - loss: 0.1787 - accuracy: 0.9483 - val_loss: 2.2864 - val_accuracy: 0.6331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe65253c4f0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, labels, epochs=20, validation_split=0.1, initial_epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"midas_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if model was successfully saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model=load_model(\"midas_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 24, 24, 112)       2912      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 20, 48)        134448    \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4800)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 112)               537712    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 63)                7119      \n",
      "=================================================================\n",
      "Total params: 682,191\n",
      "Trainable params: 682,191\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Successfully saved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
